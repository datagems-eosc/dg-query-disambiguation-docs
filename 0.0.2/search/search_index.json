{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p>Welcome to the documentation for the Query Disambiguation Service.</p> <p>This service provides an API for analyzing and disambiguating natural language queries. It identifies ambiguities, provides rephrased options, and suggests complete clarified queries using advanced LLM capabilities. The service is designed to help users clarify vague or ambiguous queries, with special focus on spatial (locations, regions) and temporal (dates, time periods) information.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Ambiguity Detection: Identifies uncertain and unclear parts in natural language queries</li> <li>Spatial &amp; Temporal Analysis: Special focus on spatial (locations, regions) and temporal (dates, time periods) information</li> <li>Rephrasing Options: Provides replacement phrases for ambiguous parts</li> <li>Suggested Queries: Generates complete rephrased queries based on disambiguation</li> <li>Clarity Assessment: Categorical clarity scoring (low/medium/high)</li> <li>Structured Output: JSON responses with detailed analysis</li> </ul>"},{"location":"#how-to-use-this-documentation","title":"How to Use This Documentation","text":"<ul> <li>System: Learn about the high-level Architecture, Security model, and system components.</li> <li>API: Find detailed information on the API endpoints, error codes, and OpenAPI specification.</li> <li>Setup &amp; Monitoring: Get instructions on Deployment, Configuration, Logging, and Automations.</li> <li>Developer Guides: Learn about Onboarding, Quality Assurance, and check the FAQ.</li> </ul>"},{"location":"api-overview/","title":"API Overview","text":"<p>The Query Disambiguation service exposes a RESTful API for analyzing and disambiguating natural language queries.</p>"},{"location":"api-overview/#base-url","title":"Base URL","text":"<p>The API is served from the root of the application. All endpoint paths are relative to the base URL where the service is deployed.</p> <p>Base URL: https://datagems-dev.scayle.es/dg-query-disambiguation/</p>"},{"location":"api-overview/#authentication","title":"Authentication","text":"<p>Currently, the API endpoints do not require authentication. See the Security page for more details. The <code>/health</code> endpoint is publicly accessible.</p>"},{"location":"api-overview/#endpoints","title":"Endpoints","text":""},{"location":"api-overview/#query-disambiguation","title":"Query Disambiguation","text":"<p>Analyzes a natural language query for ambiguity and uncertainty, providing general notes, ambiguous parts with rephrased options, overall clarity assessment, and suggested complete queries.</p> <ul> <li>Endpoint: <code>POST /query_disambiguation</code></li> <li>Description: Takes a natural language query and analyzes it for ambiguities, especially focusing on spatial and temporal information. Returns structured analysis with replacement options and suggested queries.</li> <li> <p>Request Body: <pre><code>{\n  \"query\": \"Show me the average temperature from some cities in Switzerland in the last month\",\n  \"current_datetime\": null\n}\n</code></pre></p> <ul> <li><code>query</code> (required): The natural language query to analyze (string, 1-10000 characters)</li> <li><code>current_datetime</code> (optional): Current date and time string. If not provided, will use the current system time.</li> </ul> </li> <li> <p>Response Body (Success): <pre><code>{\n  \"result\": {\n    \"general_notes\": [\n      {\n        \"aspect\": \"spatial\",\n        \"description\": \"The query specifies 'some cities in Switzerland' without identifying which cities are included. Switzerland has multiple cities, and the lack of specificity makes it unclear which data is being requested.\",\n        \"severity\": \"high\"\n      },\n      {\n        \"aspect\": \"temporal\",\n        \"description\": \"The query uses the term 'last month' which is a relative time reference. Based on the current date (2025-11-20), 'last month' refers to October 2025.\",\n        \"severity\": \"medium\"\n      }\n    ],\n    \"ambiguous_parts\": [\n      {\n        \"original_text\": \"some cities in Switzerland\",\n        \"ambiguity_type\": \"spatial\",\n        \"reason\": \"The phrase 'some cities in Switzerland' is vague because it does not specify which cities are being referred to. Switzerland has many cities, and the query does not clarify which ones are included.\",\n        \"rephrased_options\": [\n          \"Zurich, Geneva, and Bern\",\n          \"major cities in Switzerland\",\n          \"specific cities like Lausanne and Basel\"\n        ]\n      },\n      {\n        \"original_text\": \"last month\",\n        \"ambiguity_type\": \"temporal\",\n        \"reason\": \"The term 'last month' is a relative time reference that needs to be converted to a specific time period. Based on the current date, it should refer to October 2025.\",\n        \"rephrased_options\": [\n          \"October 2025\",\n          \"2025-10\"\n        ]\n      }\n    ],\n    \"overall_clarity\": \"medium\",\n    \"suggested_queries\": [\n      \"Show me the average temperature from Zurich, Geneva, and Bern in Switzerland in October 2025\",\n      \"Show me the average temperature from major cities in Switzerland in October 2025\",\n      \"Show me the average temperature from specific cities like Lausanne and Basel in Switzerland in October 2025\",\n      \"Show me the average temperature from Zurich, Geneva, and Bern in Switzerland in 2025-10\",\n      \"Show me the average temperature from major cities in Switzerland in 2025-10\",\n      \"Show me the average temperature from specific cities like Lausanne and Basel in Switzerland in 2025-10\"\n    ]\n  }\n}\n</code></pre></p> </li> <li> <p>Example Request (curl): <pre><code>curl -X POST \"https://datagems-dev.scayle.es/dg-query-disambiguation/query_disambiguation\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"Show me the average temperature from some cities in Switzerland in the last month\"\n  }'\n</code></pre></p> </li> <li> <p>Example Request (Python): <pre><code>import requests\n\nresponse = requests.post(\n    \"https://datagems-dev.scayle.es/dg-query-disambiguation/query_disambiguation\",\n    json={\n        \"query\": \"Show me the average temperature from some cities in Switzerland in the last month\"\n    }\n)\nresult = response.json()\nprint(result)\n</code></pre></p> </li> </ul>"},{"location":"api-overview/#health-check","title":"Health Check","text":"<p>Verifies the operational status of the API.</p> <ul> <li>Endpoint: <code>GET /health</code></li> <li>Description: Checks the availability of the API service. Returns a <code>200 OK</code> if the service is healthy. This endpoint does not require authentication.</li> <li>Response Body (Success): <pre><code>{\n  \"status\": \"healthy\"\n}\n</code></pre></li> </ul>"},{"location":"api-overview/#root-endpoint","title":"Root Endpoint","text":"<p>Returns basic information about the service.</p> <ul> <li>Endpoint: <code>GET /</code></li> <li>Description: Returns service name, version, and documentation links.</li> <li>Response Body (Success): <pre><code>{\n  \"service\": \"Query Disambiguation Service\",\n  \"version\": \"0.0.1\",\n  \"docs\": \"/swagger\"\n}\n</code></pre></li> </ul>"},{"location":"architecture/","title":"System Architecture","text":"<p>The Query Disambiguation Service is a self-contained application designed to analyze and disambiguate natural language queries within the DataGEMS ecosystem.</p>"},{"location":"architecture/#core-components","title":"Core Components","text":"<ol> <li> <p>FastAPI Application: The heart of the service is a Python web application built with FastAPI. It exposes the REST API, handles incoming HTTP requests, and orchestrates all internal operations.</p> </li> <li> <p>Query Disambiguation Tool: A specialized module that uses LangChain and OpenAI LLM to analyze natural language queries for ambiguity. It identifies:</p> </li> <li> <p>General uncertainty notes (spatial, temporal, entity, scope)</p> </li> <li>Specific ambiguous parts with their types</li> <li>Replacement phrases for ambiguous parts</li> <li> <p>Complete suggested queries</p> </li> <li> <p>Date/Time Resolution: A component that automatically resolves relative time references (e.g., \"last month\", \"yesterday\") based on the current system date/time, providing specific dates as replacement options.</p> </li> <li> <p>Output Parser: Uses Pydantic models and LangChain's output parsers to ensure structured JSON responses that match the defined schema.</p> </li> </ol>"},{"location":"architecture/#request-flow","title":"Request Flow","text":""},{"location":"architecture/#query-disambiguation-flow","title":"Query Disambiguation Flow","text":"<ol> <li>A user sends a <code>POST /query_disambiguation</code> request with a natural language query.</li> <li>The service optionally receives a current date/time parameter, or uses the system's current date/time.</li> <li>The Query Disambiguation Tool uses an LLM (via LangChain) to analyze the query for ambiguities.</li> <li>The LLM identifies:</li> <li>General notes about uncertainty (especially spatial and temporal)</li> <li>Specific ambiguous parts with replacement phrase options</li> <li>Overall clarity assessment</li> <li>For relative time references, the service uses the current date/time to calculate specific dates.</li> <li>The service generates suggested complete queries by combining replacement options.</li> <li>Results are formatted as structured JSON and returned to the client.</li> </ol>"},{"location":"architecture/#technology-stack","title":"Technology Stack","text":"<ul> <li>FastAPI: Modern, fast web framework for building APIs</li> <li>LangChain: Framework for developing applications powered by language models</li> <li>OpenAI: LLM provider for query analysis</li> <li>Pydantic: Data validation using Python type annotations</li> <li>Uvicorn: ASGI server for running the FastAPI application</li> </ul>"},{"location":"architecture/#data-models","title":"Data Models","text":"<p>The service uses Pydantic models for structured data:</p> <ul> <li>QueryDisambiguationRequest: Input request with query and optional current_datetime</li> <li>QueryDisambiguationResult: Output result containing:</li> <li><code>general_notes</code>: List of uncertainty notes</li> <li><code>ambiguous_parts</code>: List of ambiguous parts with rephrased options</li> <li><code>overall_clarity</code>: Categorical clarity level (low/medium/high)</li> <li><code>suggested_queries</code>: List of complete rephrased queries</li> </ul>"},{"location":"automations/","title":"Automations","text":"<p>This project leverages GitHub Actions to automate builds, code analysis, security scanning, and documentation deployment. The following sections detail the specific workflows configured for this repository.</p>"},{"location":"automations/#dockerfile","title":"Dockerfile","text":"<p>The creation of a production-ready container image is fully automated by the <code>Dockerfile</code> in the root of the repository. This build process ensures a consistent environment for the application.</p> <ul> <li> <p>Stage 1 (Builder): This stage prepares the environment by installing all necessary build-time dependencies, including the full set of Python packages.</p> </li> <li> <p>Stage 2 (Final): This stage constructs the final, lean image by copying only the essential artifacts from the builder stage. It creates a non-root <code>appuser</code> for security, copies the application code, and sets the <code>unicorn</code> server as the entry point.</p> </li> </ul>"},{"location":"automations/#docker-image-publishing","title":"Docker image publishing","text":"<p>Workflow: <code>.github/workflows/docker-publish.yml</code></p> <p>This workflow automates the process of building and publishing the service's Docker image to the GitHub Container Registry (ghcr.io).</p> <ul> <li>Trigger: This workflow runs automatically whenever a new Git tag matching the pattern <code>v*</code> (e.g., <code>v1.0.0</code>, <code>v1.1.0</code>) is pushed to the repository.</li> <li>Process:<ol> <li>Logs into the GitHub Container Registry using a temporary <code>GITHUB_TOKEN</code>.</li> <li>Uses the <code>docker/metadata-action</code> to automatically generate appropriate Docker tags based on the Git tag.</li> <li>Builds the Docker image using the <code>Dockerfile</code>.</li> <li>Pushes the newly built and tagged image to the <code>ghcr.io/datagems-eosc/in-data-exploration</code> repository, making it available for deployment.</li> </ol> </li> </ul>"},{"location":"automations/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<p>Workflow: <code>.github/workflows/vulnerability-scan-on-demand.yml</code></p> <p>This workflow provides on-demand security scanning of the project's configuration and Docker images using the Trivy security scanner.</p> <ul> <li>Trigger: This workflow is run manually from the GitHub Actions UI (<code>workflow_dispatch</code>). It requires an <code>image_tag</code> as input to specify which published Docker image to scan.</li> <li>Process:<ol> <li>Configuration Scan: Scans the <code>Dockerfile</code> and other repository configuration files for potential security misconfigurations.</li> <li>Image Scan: Pulls the specified Docker image from the GitHub Container Registry and scans its operating system packages and Python libraries for known vulnerabilities (CVEs) with <code>CRITICAL</code> or <code>HIGH</code> severity.</li> <li>Artifacts: The JSON reports from both the configuration scan and the image scan are uploaded as build artifacts for review.</li> </ol> </li> </ul>"},{"location":"automations/#static-code-analysis","title":"Static Code Analysis","text":"<p>Workflow: <code>.github/workflows/code-scan-on-demand.yml</code></p> <p>This workflow performs in-depth static code analysis using GitHub CodeQL to find potential bugs, security vulnerabilities, and quality issues in the codebase.</p> <ul> <li>Trigger: This workflow is run manually from the GitHub Actions UI (<code>workflow_dispatch</code>).</li> <li>Process:<ol> <li>It runs two separate analysis jobs: one for the Python source code and one for the GitHub Actions workflow files themselves.</li> <li>For each language, it initializes CodeQL using an extended set of security and quality queries.</li> <li>It performs the analysis and uploads the results directly to the repository's \"Security\" tab under \"Code scanning alerts\".</li> </ol> </li> </ul>"},{"location":"automations/#code-metrics","title":"Code Metrics","text":"<p>Workflow: <code>.github/workflows/code-metrics-on-demand.yml</code></p> <p>This workflow generates a report on the complexity and maintainability of the application's Python code using the Radon library.</p> <ul> <li>Trigger: This workflow is run manually from the GitHub Actions UI (<code>workflow_dispatch</code>).</li> <li>Process:<ol> <li>Installs the <code>radon</code> Python package.</li> <li>Runs three types of analysis on the <code>src/app</code> directory:<ul> <li>Maintainability Index (MI): A score from 0-100 indicating how easy the code is to maintain.</li> <li>Cyclomatic Complexity (CC): Measures the number of independent paths through the code, indicating its complexity.</li> <li>Raw Lines of Code (LOC): Provides basic code size metrics.</li> </ul> </li> <li>The complete report is compiled into a text file and uploaded as a build artifact named <code>code-metrics-report</code>.</li> </ol> </li> </ul>"},{"location":"automations/#documentation","title":"Documentation","text":"<p>Workflow: <code>.github/workflows/deploy-docs-on-demand.yml</code></p> <p>The deployment of this documentation site is automated by a dedicated GitHub Action workflow.</p> <ul> <li>Trigger: This workflow is run manually from the GitHub Actions UI (<code>workflow_dispatch</code>).</li> <li>Process: When triggered with a version number (e.g., <code>1.0.0</code>), the workflow:<ol> <li>Installs <code>mkdocs</code>, <code>mike</code>, and other required tools.</li> <li>Builds the static HTML site from the markdown source files in the <code>docs/</code> directory.</li> <li>Uses the <code>mike</code> tool to commit the built site to the <code>gh-pages</code> branch, organized under the specified version.</li> <li>Updates the <code>latest</code> alias to point to this newly deployed version, ensuring visitors see the most recent documentation by default.</li> </ol> </li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>The Query Disambiguation service is configured using a combination of a local configuration file and environment variables.</p>"},{"location":"configuration/#configuration-files","title":"Configuration files","text":"<p>For local development, the service can be configured using a <code>.env</code> file placed in the root of the repository. The application will automatically load variables from this file on startup.</p> <p>Warning The <code>.env</code> file is intended for local development only and should be added to your <code>.gitignore</code> file to prevent committing secrets to version control.</p>"},{"location":"configuration/#example-env-file","title":"Example <code>.env</code> file","text":"<pre><code># .env\n\n# OIDC Authentication\nOIDC_ISSUER_URL=\"https://datagems-dev.scayle.es/oauth/realms/dev\"\nOIDC_AUDIENCE=\"in-data-exploration\"\nGATEWAY_API_URL=\"https://datagems-dev.scayle.es/gw\"\n\n# OpenAI Configuration\nOPENAI_API_KEY=\"sk-your-openai-api-key\"\nOPENAI_MODEL_NAME=\"gpt-4o\"\n\n# LangChain Configuration (optional, for LangSmith)\nLANGCHAIN_API_KEY=\"ls-your-langchain-api-key\"\n\n# Secrets (for local use only)\nIdpClientSecret=\"your-local-dev-secret\"\n</code></pre>"},{"location":"configuration/#environment-overrides","title":"Environment Overrides","text":"<p>In any environment, especially in production, environment variables will always override values set in the <code>.env</code> file. This is the standard and recommended way to configure the service when deploying it as a container.</p> <p>The following table lists all available configuration variables:</p> Variable Description Example OIDC_ISSUER_URL The base URL of the OIDC identity provider for token validation. https://datagems-dev.scayle.es/oauth/realms/dev OIDC_AUDIENCE The audience claim that must be present in the JWT. in-data-exploration GATEWAY_API_URL The base URL of the DataGEMS Gateway API, used to fetch user permissions. https://datagems-dev.scayle.es/gw IdpClientSecret The client secret for the identity provider. your-secret OPENAI_API_KEY The API key for accessing OpenAI services (required for LLM features). sk-... LANGCHAIN_API_KEY The API key for accessing LangChain services, e.g., LangSmith (optional). ls-... OPENAI_MODEL_NAME The name of the OpenAI model to use. gpt-4o"},{"location":"configuration/#secrets","title":"Secrets","text":"<p>Certain configuration variables contain sensitive information and must be handled securely.</p>"},{"location":"configuration/#identified-secrets","title":"Identified Secrets","text":"<ul> <li>OPENAI_API_KEY: Contains the API key for OpenAI services.</li> <li>LANGCHAIN_API_KEY: Contains the API key for LangChain services (if used).</li> <li>IdpClientSecret: The client secret used for communication with the identity provider.</li> </ul>"},{"location":"datastore/","title":"Datastores","text":"<p>The Query Disambiguation service does not interact with any data stores.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>The Query Disambiguation Service is designed for containerized deployment using Docker. This guide provides instructions for building the image, configuring the service, and understanding its dependencies.</p>"},{"location":"deployment/#docker","title":"Docker","text":"<p>The primary method for deploying the service is via a Docker container. The repository includes a <code>Dockerfile</code> for the build process.</p>"},{"location":"deployment/#dockerfile-stages","title":"Dockerfile Stages","text":"<ol> <li> <p>Builder Stage:</p> <ul> <li>Starts from a <code>python:3.11-slim</code> base image.</li> <li>Installs all Python dependencies from <code>pyproject.toml</code> using <code>uv</code>.</li> </ul> </li> <li> <p>Final Stage:</p> <ul> <li>Starts from a fresh <code>python:3.11-slim</code> image.</li> <li>Creates a non-root user (<code>appuser</code>) for security.</li> <li>Copies the installed Python packages from the builder stage.</li> <li>Copies the application source code into the container.</li> <li>Sets <code>appuser</code> as the active user.</li> <li>Exposes port <code>8080</code>.</li> <li>Includes a <code>HEALTHCHECK</code> instruction that queries the <code>/health</code> endpoint to monitor container health.</li> <li>The default command (<code>CMD</code>) starts the application using <code>uvicorn</code>, making it production-ready.</li> </ul> </li> </ol>"},{"location":"deployment/#build-and-run","title":"Build and Run","text":"<p>To build and run the container, use the standard Docker commands:</p> <pre><code># 1. Build the Docker image\ndocker build -t in-data-exploration .\n\n# 2. Run the container\n# Note: You must provide all required environment variables.\ndocker run -p 8080:8080 \\\n  --env-file .env \\\n  --name in-data-exploration-service \\\n  in-data-exploration\n</code></pre>"},{"location":"deployment/#configuration","title":"Configuration","text":"<p>The service is configured entirely through environment variables. This allows for flexible deployment across different environments without changing the container image.</p> Variable Description Example OIDC_ISSUER_URL The base URL of the OIDC identity provider for token validation. https://datagems-dev.scayle.es/oauth/realms/dev OIDC_AUDIENCE The audience claim that must be present in the JWT. in-data-exploration GATEWAY_API_URL The base URL of the DataGEMS Gateway API, used to fetch user permissions. https://datagems-dev.scayle.es/gw IdpClientSecret The client secret for the identity provider (taken as secret from Vault). your-secret OPENAI_API_KEY The API key for accessing OpenAI services (required for LLM features). sk-... LANGCHAIN_API_KEY The API key for accessing LangChain services, e.g., LangSmith. ls-... OPENAI_MODEL_NAME The name of the OpenAI model to use. gpt-4o"},{"location":"deployment/#dependencies","title":"Dependencies","text":"<p>The service requires several external systems and resources to be available at runtime to function correctly.</p>"},{"location":"deployment/#runtime-dependencies","title":"Runtime Dependencies","text":"<p>OpenAI API: - Description: Required for LLM-powered features including text-to-SQL conversion. - Requirement: A valid <code>OPENAI_API_KEY</code> must be configured.</p> <p>OIDC Provider: - Description: An OpenID Connect compliant identity provider (e.g., Keycloak) is necessary for authenticating users by validating their JWTs (for protected endpoints). - Requirement: The <code>OIDC_ISSUER_URL</code> and <code>OIDC_AUDIENCE</code> must be correctly configured to point to the identity provider.</p> <p>DataGEMS Gateway (Optional): - Description: The service may communicate with the DataGEMS Gateway API to fetch dataset-level permissions for users. - Requirement: The <code>GATEWAY_API_URL</code> must be configured if gateway integration is needed.</p>"},{"location":"error-codes/","title":"Status &amp; Error Codes","text":"<p>The Query Disambiguation Service uses standard HTTP status codes to indicate the success or failure of API requests.</p>"},{"location":"error-codes/#success-codes","title":"Success Codes","text":""},{"location":"error-codes/#200-ok","title":"200 OK","text":"<p>The request was successful.</p> <p>Example: <pre><code>{\n  \"result\": {\n    \"general_notes\": [...],\n    \"ambiguous_parts\": [...],\n    \"overall_clarity\": \"medium\",\n    \"suggested_queries\": [...]\n  }\n}\n</code></pre></p>"},{"location":"error-codes/#client-error-codes","title":"Client Error Codes","text":""},{"location":"error-codes/#400-bad-request","title":"400 Bad Request","text":"<p>The request was malformed or invalid.</p> <p>Common causes: - Missing required fields - Invalid JSON format - Query length exceeds maximum (10,000 characters) - Invalid date/time format</p> <p>Example Response: <pre><code>{\n  \"detail\": \"query field is required\"\n}\n</code></pre></p>"},{"location":"error-codes/#422-unprocessable-entity","title":"422 Unprocessable Entity","text":"<p>The request was well-formed but contains semantic errors.</p> <p>Common causes: - Validation errors in request body - Invalid data types</p> <p>Example Response: <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"body\", \"query\"],\n      \"msg\": \"field required\",\n      \"type\": \"value_error.missing\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"error-codes/#server-error-codes","title":"Server Error Codes","text":""},{"location":"error-codes/#500-internal-server-error","title":"500 Internal Server Error","text":"<p>An unexpected error occurred on the server.</p> <p>Common causes: - OpenAI API errors - LLM processing failures - Internal service errors</p> <p>Example Response: <pre><code>{\n  \"detail\": \"An error occurred during disambiguation: [error message]\"\n}\n</code></pre></p>"},{"location":"error-codes/#error-response-format","title":"Error Response Format","text":"<p>All error responses follow this format:</p> <pre><code>{\n  \"detail\": \"Error message describing what went wrong\"\n}\n</code></pre> <p>For validation errors (422), the detail may be an array of validation errors:</p> <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"body\", \"field_name\"],\n      \"msg\": \"Error message\",\n      \"type\": \"error_type\"\n    }\n  ]\n}\n</code></pre>"},{"location":"error-codes/#handling-errors","title":"Handling Errors","text":"<p>When making API requests, always check the HTTP status code:</p> <pre><code>import requests\n\nresponse = requests.post(\n    \"https://datagems-dev.scayle.es/dg-query-disambiguation/query_disambiguation\",\n    json={\"query\": \"test query\"}\n)\n\nif response.status_code == 200:\n    result = response.json()\n    # Process successful response\nelif response.status_code == 400:\n    print(f\"Bad request: {response.json()['detail']}\")\nelif response.status_code == 500:\n    print(f\"Server error: {response.json()['detail']}\")\nelse:\n    print(f\"Unexpected status: {response.status_code}\")\n</code></pre>"},{"location":"faq/","title":"FAQ &amp; Known Issues","text":"<p>Frequently asked questions and known issues for the Query Disambiguation Service.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-the-query-disambiguation-service","title":"What is the Query Disambiguation Service?","text":"<p>The Query Disambiguation Service analyzes natural language queries to identify ambiguities, provide rephrased options, and suggest complete clarified queries. It's particularly focused on spatial and temporal information.</p>"},{"location":"faq/#what-models-does-it-support","title":"What models does it support?","text":"<p>The service uses OpenAI models. The default is <code>gpt-4o-mini</code>, but you can configure other models via the <code>OPENAI_MODEL_NAME</code> environment variable.</p>"},{"location":"faq/#is-authentication-required","title":"Is authentication required?","text":"<p>Currently, the service does not require authentication. All endpoints are publicly accessible. See Security for details.</p>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#how-do-i-resolve-relative-time-references","title":"How do I resolve relative time references?","text":"<p>The service automatically resolves relative time references (e.g., \"last month\", \"yesterday\") based on the current date/time. You can optionally provide a <code>current_datetime</code> parameter in the request, or the service will use the system's current time.</p>"},{"location":"faq/#what-is-the-maximum-query-length","title":"What is the maximum query length?","text":"<p>The maximum query length is 10,000 characters.</p>"},{"location":"faq/#how-long-does-disambiguation-take","title":"How long does disambiguation take?","text":"<p>Response time depends on: - Query complexity - OpenAI API latency - Model used</p> <p>Typical response time is 2-5 seconds.</p>"},{"location":"faq/#can-i-use-my-own-llm","title":"Can I use my own LLM?","text":"<p>The service is currently designed for OpenAI models. To use other providers, you would need to modify the <code>QueryDisambiguationTool</code> class in <code>src/tools/query_disambiguation.py</code>.</p>"},{"location":"faq/#technical-questions","title":"Technical Questions","text":""},{"location":"faq/#how-do-i-change-the-openai-model","title":"How do I change the OpenAI model?","text":"<p>Set the <code>OPENAI_MODEL_NAME</code> environment variable: <pre><code>export OPENAI_MODEL_NAME='gpt-4o'\n</code></pre></p> <p>Or pass it when initializing the tool: <pre><code>tool = QueryDisambiguationTool(model_name='gpt-4o')\n</code></pre></p>"},{"location":"faq/#how-do-i-handle-errors","title":"How do I handle errors?","text":"<p>The service returns standard HTTP status codes: - <code>200</code>: Success - <code>400</code>: Bad request - <code>422</code>: Validation error - <code>500</code>: Server error</p> <p>See Error Codes for details.</p>"},{"location":"faq/#can-i-run-multiple-instances","title":"Can I run multiple instances?","text":"<p>Yes, the service is stateless and can be horizontally scaled. Run multiple instances behind a load balancer.</p>"},{"location":"faq/#known-issues","title":"Known Issues","text":""},{"location":"faq/#issue-slow-response-times","title":"Issue: Slow response times","text":"<p>Cause: OpenAI API latency or rate limiting</p> <p>Solution: - Check OpenAI API status - Verify API key has sufficient quota - Consider using a faster model (e.g., gpt-4o-mini) - Implement caching for frequent queries</p>"},{"location":"faq/#issue-inconsistent-results","title":"Issue: Inconsistent results","text":"<p>Cause: LLM non-determinism</p> <p>Solution: - Lower the temperature parameter (default: 0.3) - Use a more deterministic model - Implement result caching</p>"},{"location":"faq/#issue-high-api-costs","title":"Issue: High API costs","text":"<p>Cause: Frequent API calls to OpenAI</p> <p>Solution: - Use gpt-4o-mini (more cost-effective) - Implement caching - Monitor usage and set budgets - Consider batch processing</p>"},{"location":"faq/#issue-timezone-handling","title":"Issue: Timezone handling","text":"<p>Current behavior: Uses system timezone</p> <p>Workaround: Provide explicit <code>current_datetime</code> in requests with timezone information</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#service-wont-start","title":"Service won't start","text":"<ol> <li>Check <code>OPENAI_API_KEY</code> is set</li> <li>Verify Python version (3.11+)</li> <li>Check port 8000 is available</li> <li>Review error logs</li> </ol>"},{"location":"faq/#api-returns-500-errors","title":"API returns 500 errors","text":"<ol> <li>Check OpenAI API key is valid</li> <li>Verify API key has quota</li> <li>Check service logs for details</li> <li>Verify network connectivity to OpenAI</li> </ol>"},{"location":"faq/#results-are-inaccurate","title":"Results are inaccurate","text":"<ol> <li>Try a different model</li> <li>Adjust temperature parameter</li> <li>Provide more context in queries</li> <li>Check if query is too ambiguous</li> </ol>"},{"location":"faq/#performance","title":"Performance","text":""},{"location":"faq/#how-many-requests-per-second-can-it-handle","title":"How many requests per second can it handle?","text":"<p>Depends on: - OpenAI API rate limits - Server resources - Query complexity</p> <p>For production, implement rate limiting and consider horizontal scaling.</p>"},{"location":"faq/#how-do-i-improve-performance","title":"How do I improve performance?","text":"<ol> <li>Use faster models (gpt-4o-mini)</li> <li>Implement caching</li> <li>Scale horizontally</li> <li>Optimize queries</li> </ol>"},{"location":"faq/#cost-management","title":"Cost Management","text":""},{"location":"faq/#how-much-does-it-cost","title":"How much does it cost?","text":"<p>Costs depend on: - Model used (gpt-4o-mini is cheaper) - Query length - Number of requests</p> <p>Monitor usage via OpenAI dashboard.</p>"},{"location":"faq/#how-do-i-reduce-costs","title":"How do I reduce costs?","text":"<ol> <li>Use gpt-4o-mini</li> <li>Implement caching</li> <li>Batch requests when possible</li> <li>Set usage limits</li> </ol>"},{"location":"faq/#support","title":"Support","text":""},{"location":"faq/#where-can-i-get-help","title":"Where can I get help?","text":"<ul> <li>Check documentation</li> <li>Review GitHub issues</li> <li>Contact maintainers</li> <li>Check OpenAI API documentation</li> </ul>"},{"location":"faq/#how-do-i-report-a-bug","title":"How do I report a bug?","text":"<p>Create an issue on GitHub with: - Description of the issue - Steps to reproduce - Expected vs actual behavior - Environment details - Relevant logs</p>"},{"location":"license/","title":"License","text":""},{"location":"logging/","title":"Logging &amp; Accounting","text":"<p>The service uses <code>structlog</code> for structured, JSON-formatted logging.</p>"},{"location":"logging/#log-structure","title":"Log Structure","text":"<p>All log entries are formatted as JSON objects with a consistent structure, including:</p> <ul> <li><code>@t</code>: ISO 8601 timestamp.</li> <li><code>@mt</code>: The log message (event).</li> <li><code>@l</code>: The log level (e.g., \"Info\", \"Warning\", \"Error\").</li> <li><code>DGCorrelationId</code>: A unique ID that ties together all log entries for a single HTTP request.</li> <li><code>SourceContext</code>: The name of the logger that produced the message.</li> <li><code>Application</code>: The name of the application (<code>in-data-exploration-api</code>).</li> </ul> <p>Additional key-value pairs are added to provide context for specific events.</p>"},{"location":"logging/#correlation-id","title":"Correlation ID","text":"<p>Every HTTP request is assigned a correlation ID. - If the incoming request includes an <code>x-tracking-correlation</code> header, its value is used. - Otherwise, a new UUID is generated.</p> <p>This ID is included in every log message generated during the processing of that request and is also returned in the <code>x-tracking-correlation</code> response header. This allows for easy tracing of a request's entire lifecycle through the system and across different services.</p>"},{"location":"logging/#request-logging","title":"Request Logging","text":"<p>A middleware automatically logs the end of every HTTP request (except for health checks), capturing:</p> <ul> <li><code>RequestMethod</code> (e.g., GET, POST)</li> <li><code>RequestPath</code></li> <li><code>StatusCode</code></li> <li><code>ProcessTimeMS</code></li> <li><code>ResponseSize</code></li> </ul>"},{"location":"maintenance/","title":"Maintenance","text":"<p>This document outlines key maintenance tasks for the In-Dataset Discovery Service.</p>"},{"location":"maintenance/#regular-maintenance-tasks","title":"Regular Maintenance Tasks","text":""},{"location":"maintenance/#monitoring-service-health","title":"Monitoring Service Health","text":"<p>Regularly monitor the service health using the <code>/health</code> endpoint to ensure all components are functioning correctly.</p>"},{"location":"maintenance/#api-key-management","title":"API Key Management","text":"<ul> <li>OpenAI API Key: Monitor usage and ensure the API key remains valid. Rotate keys periodically for security.</li> <li>LangChain API Key: If using LangSmith, monitor usage and ensure the key is valid.</li> </ul>"},{"location":"maintenance/#dependency-updates","title":"Dependency Updates","text":"<p>Regularly update dependencies to: - Fix security vulnerabilities - Get bug fixes and performance improvements - Stay compatible with external services (Overpass API, OpenAI API, etc.)</p>"},{"location":"maintenance/#log-monitoring","title":"Log Monitoring","text":"<p>Monitor application logs for: - Error patterns that may indicate issues - Performance degradation - Authentication/authorization failures - Downstream service failures (OpenAI, Overpass API, etc.)</p>"},{"location":"maintenance/#database-connection-management","title":"Database Connection Management","text":"<p>For the <code>/query_disambiguation</code> endpoint: - Monitor database connection performance - Ensure proper connection pooling if implemented - Validate that user-provided database credentials are handled securely</p>"},{"location":"maintenance/#troubleshooting","title":"Troubleshooting","text":""},{"location":"maintenance/#common-issues","title":"Common Issues","text":"<ol> <li>OpenAI API Errors: Check API key validity, rate limits, and service status.</li> <li>Authentication Failures: Verify OIDC provider configuration and token validity.</li> </ol>"},{"location":"maintenance/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Monitor response times for each endpoint</li> <li>Consider caching frequently accessed data (e.g., Wikidata lookups)</li> <li>Optimize LLM prompts to reduce token usage and improve response times</li> <li>Monitor and optimize database query performance for text-to-SQL operations</li> </ul>"},{"location":"onboarding/","title":"Developer Onboarding Guide","text":"<p>Welcome to the developer guide for the In-Dataset Discovery Service.</p> <p>This document provides a comprehensive overview of the service's architecture and a step-by-step guide for extending it with new features, agents, and tools.</p>"},{"location":"onboarding/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Developer Onboarding Guide</li> <li>Table of Contents</li> <li>1. Service Overview<ul> <li>Core Principles</li> <li>Directory Structure</li> <li>Key Components</li> </ul> </li> <li>2. System Architecture<ul> <li>API Layer</li> <li>Agent Layer</li> <li>Tool Layer</li> </ul> </li> <li>3. Adding New Features<ul> <li>Adding a New API Endpoint</li> <li>Adding a New Tool</li> </ul> </li> <li>4. Development Workflow<ul> <li>Local Setup</li> <li>Testing</li> <li>Code Style</li> <li>Best Practices</li> </ul> </li> <li>Next Steps</li> </ul>"},{"location":"onboarding/#1-service-overview","title":"1. Service Overview","text":"<p>The In-Dataset Discovery Service is a FastAPI-based application that provides natural language interfaces for exploring datasets. It uses LLM capabilities to convert user questions into executable queries and agents to orchestrate complex multi-step tasks.</p>"},{"location":"onboarding/#core-principles","title":"Core Principles","text":"<p>The service is built on a few key principles:</p> <ul> <li>Modularity: Each component (agents, tools, models) is self-contained and can be extended independently.</li> <li>LLM-Powered: Leverages LLM and LangChain for intelligent query generation and processing.</li> <li>Agent-Based: Uses LangGraph to orchestrate complex workflows that combine multiple tools.</li> <li>Type Safety: Uses Pydantic models for request/response validation and type safety.</li> </ul>"},{"location":"onboarding/#directory-structure","title":"Directory Structure","text":"<pre><code>dg-query-disambiguation/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 main.py              # FastAPI application\n\u2502   \u2502   \u251c\u2500\u2500 schemas.py           # Request/Response models\n\u2502   \u2502   \u2514\u2500\u2500 dependencies.py      # Dependency injection\n\u2502   \u2514\u2500\u2500 tools/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 query_disambiguation.py  # Core disambiguation tool\n\u251c\u2500\u2500 main.py                      # Application entry point\n\u251c\u2500\u2500 example.py                   # Usage examples\n\u251c\u2500\u2500 pyproject.toml              # Project configuration\n\u251c\u2500\u2500 README.md                   # This file\n\u2514\u2500\u2500 .env                        # Environment variables (not in git)\n</code></pre>"},{"location":"onboarding/#key-components","title":"Key Components","text":"<ol> <li>FastAPI Application (<code>src/app/main.py</code>): Defines all API endpoints and request/response models.</li> <li>Tools (<code>src/tools/</code>): Reusable functions that agents can call:</li> <li><code>query_disambiguation.py</code>: Tool for disambiguating natural language queries</li> </ol>"},{"location":"onboarding/#2-system-architecture","title":"2. System Architecture","text":""},{"location":"onboarding/#api-layer","title":"API Layer","text":"<p>The API layer (<code>src/app/main.py</code>) handles HTTP requests and responses. Each endpoint:</p> <ul> <li>Validates input using Pydantic models</li> <li>Handles authentication (if required) (not implemented yet)</li> <li>Calls the appropriate tool</li> <li>Returns structured responses</li> </ul>"},{"location":"onboarding/#agent-layer","title":"Agent Layer","text":"<p>Agents are the core processing units that handle specific types of queries:</p> <ul> <li>Query Disambiguation Agent: Processes natural language queries and disambiguates them</li> </ul>"},{"location":"onboarding/#tool-layer","title":"Tool Layer","text":"<p>Tools are reusable functions that agents can invoke. They encapsulate specific operations like: - Disambiguating natural language queries</p>"},{"location":"onboarding/#3-adding-new-features","title":"3. Adding New Features","text":""},{"location":"onboarding/#adding-a-new-api-endpoint","title":"Adding a New API Endpoint","text":"<ol> <li>Define Request/Response Models in <code>src/app/main.py</code>:</li> </ol> <pre><code>class MyQueryRequest(BaseModel):\n    question: str = Field(..., description=\"The question to process\")\n\nclass MyQueryResponse(BaseModel):\n    answer: str\n    metadata: Dict[str, Any]\n</code></pre> <ol> <li>Create the Endpoint:</li> </ol> <pre><code>@app.post(\"/my-endpoint\", response_model=MyQueryResponse)\nasync def my_endpoint(query: MyQueryRequest):\n    \"\"\"Process a query and return results.\"\"\"\n    # Your logic here\n    result = process_query(query.question)\n    return MyQueryResponse(answer=result, metadata={})\n</code></pre> <ol> <li>Add Error Handling:</li> </ol> <pre><code>try:\n    result = process_query(query.question)\n    return MyQueryResponse(answer=result, metadata={})\nexcept Exception as e:\n    logger.error(\"query_failed\", error=str(e))\n    raise HTTPException(status_code=500, detail=str(e))\n</code></pre> <ol> <li>Add Tools (if needed) in <code>src/tools/</code>:</li> </ol> <pre><code># src/agents/tools/my_tool.py\ndef my_tool(param: str) -&gt; Dict[str, Any]:\n    \"\"\"A tool that does something useful.\"\"\"\n    # Tool implementation\n    return {\"result\": \"value\"}\n</code></pre> <ol> <li>Integrate with API in <code>src/app/main.py</code>:</li> </ol> <pre><code>from src.agents.my_agent import my_agent\n\n@app.get(\"/my-endpoint\")\nasync def my_endpoint(question: str, log: structlog.BoundLogger = Depends(get_logger)):\n    return my_agent(question, log)\n</code></pre>"},{"location":"onboarding/#adding-a-new-tool","title":"Adding a New Tool","text":"<ol> <li>Create Tool File in <code>src/tools/</code>:</li> </ol> <pre><code># src/agents/tools/my_tool.py\nfrom typing import Dict, Any\n\ndef my_tool(param1: str, param2: int) -&gt; Dict[str, Any]:\n    \"\"\"\n    Tool description.\n\n    Args:\n        param1: Description of param1\n        param2: Description of param2\n\n    Returns:\n        Dictionary with results\n    \"\"\"\n    # Tool implementation\n    return {\"result\": \"value\"}\n</code></pre>"},{"location":"onboarding/#4-development-workflow","title":"4. Development Workflow","text":""},{"location":"onboarding/#local-setup","title":"Local Setup","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone git@github.com:datagems-eosc/dg-query-disambiguation.git\ncd dg-query-disambiguation\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code># Using uv (recommended)\nuv sync\n\n# Or using pip\npip install -e .\n</code></pre></p> </li> <li> <p>Set up environment variables: <pre><code>cp .env.template .env\n# Edit .env with your configuration\n</code></pre></p> </li> <li> <p>Run the service: <pre><code># Using uvicorn directly\nuvicorn src.app.main:app --reload --port 8080\n\n# Or using Docker\ndocker build -t dg-query-disambiguation .\ndocker run --env-file .env -p 8080:8080 dg-query-disambiguation\n</code></pre></p> </li> </ol>"},{"location":"onboarding/#testing","title":"Testing","text":"<ol> <li>Run health check:</li> </ol> <pre><code>curl https://datagems-dev.scayle.es/health\n</code></pre> <ol> <li>Test an endpoint:</li> </ol> <pre><code>curl -X POST \"https://datagems-dev.scayle.es/dg-query-disambiguation/query_disambiguation\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"Show me the data from that place last month\"\n  }'\n</code></pre> <ol> <li> <p>View API documentation:</p> </li> <li> <p>Swagger UI: https://datagems-dev.scayle.es/dg-query-disambiguation/swagger</p> </li> <li>ReDoc: https://datagems-dev.scayle.es/dg-query-disambiguation/redoc</li> </ol>"},{"location":"onboarding/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8 style guidelines</li> <li>Use type hints for all function parameters and return values</li> <li>Use Pydantic models for data validation</li> <li>Add docstrings to all public functions and classes</li> <li>Use structured logging with <code>structlog</code></li> <li>Handle errors gracefully and return appropriate HTTP status codes</li> </ul>"},{"location":"onboarding/#best-practices","title":"Best Practices","text":"<ol> <li>Error Handling: Always wrap agent calls in try-except blocks and log errors appropriately.</li> <li>Logging: Use structured logging with context (user ID, correlation ID, etc.).</li> <li>Validation: Use Pydantic models for all request/response validation.</li> <li>Security: Follow the security patterns established in <code>src/app/security.py</code> for protected endpoints.</li> <li>Testing: Write tests for new features and ensure they pass before submitting PRs.</li> </ol>"},{"location":"onboarding/#next-steps","title":"Next Steps","text":"<ul> <li>Review the Architecture documentation for more details on system design</li> <li>Check the API Overview to understand existing endpoints</li> <li>Read the Configuration guide for environment setup</li> <li>Explore the source code in <code>src/agents/</code> to see examples of agent implementations</li> </ul>"},{"location":"openapi/","title":"OpenAPI Specification","text":""},{"location":"openapi/#query-disambiguation-service-002","title":"Query Disambiguation Service 0.0.2","text":"<p>DataGEMS API for analyzing and disambiguating natural language queries</p>"},{"location":"openapi/#endpoints","title":"Endpoints","text":""},{"location":"openapi/#get","title":"GET /","text":"<p>Root</p> Description <p>Root endpoint.</p> <p> Response 200 OK </p> application/json Schema of the response body"},{"location":"openapi/#get-health","title":"GET /health","text":"<p>Health Check</p> Description <p>Health check endpoint.</p> <p> Response 200 OK </p> application/json Schema of the response body"},{"location":"openapi/#query-disambiguation","title":"Query Disambiguation","text":""},{"location":"openapi/#post-query_disambiguation","title":"POST /query_disambiguation","text":"<p>Disambiguate a natural language query</p> Description <p>Analyzes a natural language query for ambiguity and uncertainty, providing general notes, ambiguous parts with rephrased options, overall clarity assessment, and suggested complete queries.</p> <p>Request body</p> application/json <p><pre><code>{\n    \"query\": \"Show me the average temperature from some cities in Switzerland in the last month\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the request body <pre><code>{\n    \"description\": \"Request schema for query disambiguation endpoint.\",\n    \"example\": {\n        \"query\": \"Show me the average temperature from some cities in Switzerland in the last month\"\n    },\n    \"properties\": {\n        \"current_datetime\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"string\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"description\": \"Current date and time string. If not provided, will use the current system time.\",\n            \"title\": \"Current Datetime\"\n        },\n        \"query\": {\n            \"description\": \"The natural language query to analyze for ambiguity\",\n            \"maxLength\": 10000,\n            \"minLength\": 1,\n            \"title\": \"Query\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"query\"\n    ],\n    \"title\": \"QueryDisambiguationRequest\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"result\": {\n        \"ambiguous_parts\": [\n            {\n                \"ambiguity_type\": \"spatial\",\n                \"original_text\": \"that place\",\n                \"reason\": \"Vague reference without context\",\n                \"rephrased_options\": [\n                    \"New York\",\n                    \"the headquarters\"\n                ]\n            }\n        ],\n        \"general_notes\": [\n            {\n                \"aspect\": \"spatial\",\n                \"description\": \"The query refers to 'that place' without specifying a location.\",\n                \"severity\": \"high\"\n            }\n        ],\n        \"overall_clarity\": \"low\",\n        \"suggested_queries\": [\n            \"Show me the data from New York last month\"\n        ]\n    }\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"description\": \"Response schema for query disambiguation endpoint.\",\n    \"example\": {\n        \"result\": {\n            \"ambiguous_parts\": [\n                {\n                    \"ambiguity_type\": \"spatial\",\n                    \"original_text\": \"that place\",\n                    \"reason\": \"Vague reference without context\",\n                    \"rephrased_options\": [\n                        \"New York\",\n                        \"the headquarters\"\n                    ]\n                }\n            ],\n            \"general_notes\": [\n                {\n                    \"aspect\": \"spatial\",\n                    \"description\": \"The query refers to 'that place' without specifying a location.\",\n                    \"severity\": \"high\"\n                }\n            ],\n            \"overall_clarity\": \"low\",\n            \"suggested_queries\": [\n                \"Show me the data from New York last month\"\n            ]\n        }\n    },\n    \"properties\": {\n        \"result\": {\n            \"$ref\": \"#/components/schemas/QueryDisambiguationResult\",\n            \"description\": \"The disambiguation analysis result\"\n        }\n    },\n    \"required\": [\n        \"result\"\n    ],\n    \"title\": \"QueryDisambiguationResponse\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#schemas","title":"Schemas","text":""},{"location":"openapi/#ambiguouspart","title":"AmbiguousPart","text":"Name Type <code>ambiguity_type</code> string <code>original_text</code> string <code>reason</code> string <code>rephrased_options</code> Array&lt;string&gt;"},{"location":"openapi/#httpvalidationerror","title":"HTTPValidationError","text":"Name Type <code>detail</code> Array&lt;ValidationError&gt;"},{"location":"openapi/#querydisambiguationrequest","title":"QueryDisambiguationRequest","text":"Name Type <code>current_datetime</code> <code>query</code> string"},{"location":"openapi/#querydisambiguationresponse","title":"QueryDisambiguationResponse","text":"Name Type <code>result</code> QueryDisambiguationResult"},{"location":"openapi/#querydisambiguationresult","title":"QueryDisambiguationResult","text":"Name Type <code>ambiguous_parts</code> Array&lt;AmbiguousPart&gt; <code>general_notes</code> Array&lt;UncertaintyNote&gt; <code>overall_clarity</code> string <code>suggested_queries</code> Array&lt;string&gt;"},{"location":"openapi/#uncertaintynote","title":"UncertaintyNote","text":"Name Type <code>aspect</code> string <code>description</code> string <code>severity</code> string"},{"location":"openapi/#validationerror","title":"ValidationError","text":"Name Type <code>loc</code> Array&lt;&gt; <code>msg</code> string <code>type</code> string"},{"location":"qa/","title":"Quality Assurance","text":"<p>Quality assurance (QA) combines automated static analysis, vulnerability scanning, and API-level integration testing to ensure the service functions as expected.</p>"},{"location":"qa/#code-analysis","title":"Code Analysis","text":"<p>We use GitHub CodeQL for static analysis of the source code. This process helps identify potential bugs, security vulnerabilities, and quality issues before they impact production.</p> <ul> <li>Technology: GitHub CodeQL</li> <li>Targets: The analysis runs on both the Python source code and the GitHub Actions workflow files themselves.</li> <li>Checks: It uses a set of queries to find common vulnerabilities (e.g., injection flaws, insecure data handling), bugs, and code quality anti-patterns.</li> <li>Execution: The analysis is performed by the on-demand <code>code-scan-on-demand.yml</code> workflow. Results and alerts are available directly in the repository's \"Security\" tab.</li> </ul>"},{"location":"qa/#code-metrics","title":"Code Metrics","text":"<p>To ensure the long-term maintainability and readability of the code, we use the Radon library to generate code metrics.</p> <ul> <li>Technology: Radon</li> <li>Metrics:<ul> <li>Maintainability Index (MI): A score from 0-100 indicating how easy the code is to maintain (higher is better).</li> <li>Cyclomatic Complexity (CC): Measures the number of independent paths through the code. A lower score indicates simpler, less complex code.</li> <li>Lines of Code (LOC): Provides raw metrics on the size of the codebase.</li> </ul> </li> <li>Execution: The metrics are generated by the on-demand <code>code-metrics-on-demand.yml</code> workflow, which produces a downloadable <code>code-metrics-report.txt</code> artifact.</li> </ul>"},{"location":"qa/#vulnerability-checks","title":"Vulnerability Checks","text":"<p>We use Trivy to scan for known vulnerabilities in our dependencies and container image, ensuring the service is secure from common threats.</p> <ul> <li>Technology: Trivy</li> <li>Scans:<ol> <li>Configuration Scan: Scans the <code>Dockerfile</code> and other repository files for security misconfigurations.</li> <li>Image Scan: Scans the final Docker image for known vulnerabilities (CVEs) with <code>CRITICAL</code> or <code>HIGH</code> severity in its OS packages and Python libraries.</li> </ol> </li> <li>Execution: The scan is performed by the on-demand <code>vulnerability-scan-on-demand.yml</code> workflow. It requires an image tag as input and uploads detailed JSON reports as build artifacts.</li> </ul>"},{"location":"qa/#testing","title":"Testing","text":"<p>The service's functionality is validated through API-level integration tests using Postman and its command-line runner, Newman.</p> <ul> <li> <p>Test Suite: The test cases are defined in the Postman collection located at <code>tests/in-data-exploration-api-tests.postman_collection.json</code> (if available).</p> </li> <li> <p>Test Cases: The suite may include the following tests:</p> <ul> <li>Health Check: Verifies that the <code>/health</code> endpoint is available and returns a <code>200 OK</code> status, indicating the service is healthy.</li> <li>Geospatial Query - Valid Request: Executes a valid geospatial query against the <code>/geospatial</code> endpoint and asserts that the response is successful (<code>200 OK</code>) and has the correct structure.</li> <li>Text-to-SQL Query - Valid Request: Executes a valid text-to-SQL query against the <code>/text2sql</code> endpoint and asserts that the response is successful (<code>200 OK</code>) and contains the generated SQL and results.</li> </ul> </li> </ul>"},{"location":"qa/#how-to-run-tests","title":"How to Run Tests","text":"<p>The API tests are designed to be run automatically via a GitHub Actions workflow.</p> <ul> <li>Workflow File: <code>.github/workflows/test-on-demand.yml</code></li> <li>Trigger: The workflow is triggered manually (<code>workflow_dispatch</code>) from the Actions tab in the GitHub repository.</li> <li>Process:<ol> <li>Navigate to the \"Actions\" tab and select the \"Test Scenario (On-Demand)\" workflow.</li> <li>Click \"Run workflow\". You will be prompted to enter a <code>tag</code> (e.g., <code>main</code> or a specific version like <code>v1.0.0</code>) to test against.</li> <li>The workflow checks out the specified version of the code.</li> <li>It then uses the official <code>postman/newman</code> Docker image to execute the test collection.</li> <li>All necessary environment variables (API base URL, credentials, etc.) are securely injected into the test run from the repository's secrets.</li> </ol> </li> </ul>"},{"location":"qa/#expected-output","title":"Expected Output","text":"<p>A successful test run will produce the following summary table in the GitHub Actions log:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         \u2502            executed \u2502             failed \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502              iterations \u2502                   1 \u2502                  0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                requests \u2502                   4 \u2502                  0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502            test-scripts \u2502                   4 \u2502                  0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      prerequest-scripts \u2502                   0 \u2502                  0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502              assertions \u2502                   4 \u2502                  0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 total run duration: 1674ms                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 total data received: 6.9kB (approx)                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 average response time: 396ms [min: 147ms, max: 645ms, s.d.: 205ms] \u2502\n</code></pre>"},{"location":"security/","title":"Security","text":""},{"location":"security/#authentication","title":"Authentication","text":"<p>Authentication is handled via the OAuth 2.0 and OpenID Connect (OIDC) protocols. Every request to a protected endpoint must include a valid JSON Web Token (JWT) in the <code>Authorization</code> header as a Bearer token.</p> <p>The service validates incoming JWTs against the OIDC provider's public keys. The token's signature, issuer, and audience are all verified to ensure its authenticity.</p>"},{"location":"security/#authorization","title":"Authorization","text":"<p>Authorization is role-based. The service checks for specific roles within the validated JWT's claims.</p> <ul> <li>Required Roles: The <code>/query_disambiguation</code> endpoint may have different authentication requirements depending on the deployment configuration. The <code>/health</code> endpoint is publicly accessible.</li> </ul> <p>If a user attempts to access an endpoint without the required role, the API will respond with a <code>403 Forbidden</code> error.</p>"},{"location":"security/#dataset-level-permissions","title":"Dataset-Level Permissions","text":"<p>This service has not implemented dataset-level permissions.</p>"}]}